{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77b9b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00       146\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Saved 676 reminders.\n",
      "\n",
      "Customer segments distribution:\n",
      "Critical           622\n",
      "High Priority       41\n",
      "Medium Priority     13\n",
      "Name: customer_segment, dtype: int64\n",
      "\n",
      "Preferred communication channels distribution:\n",
      "Email       676\n",
      "WhatsApp    663\n",
      "Phone       622\n",
      "SMS          13\n",
      "Name: preferred_channels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Custom transformer to extract sentiment polarity from feedback text\n",
    "class FeedbackSentimentExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([TextBlob(str(text)).sentiment.polarity if pd.notna(text) else 0 for text in X]).reshape(-1, 1)\n",
    "\n",
    "# Example dataset load\n",
    "df = pd.read_csv('modify_service_df.csv')\n",
    "\n",
    "# Target: Whether customer needs urgent reminder \n",
    "# Ideally based on actual historical labels (response to reminder or actual service)\n",
    "# For demo, simulate using criteria as in your code\n",
    "df['service_urgent'] = np.where(\n",
    "    (df['next_service_due_days'] <= 120) |\n",
    "    (df['feedback_score'] <= 2) |\n",
    "    (df['customer_feedback'].isin(['Poor Service', 'Unresponsive', 'Delayed Pickup'])),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Define features: structured + raw feedback text\n",
    "numeric_features = [\n",
    "    'feedback_score',\n",
    "    'last_service_cost',\n",
    "    'days_since_last_service',\n",
    "    'next_service_due_days',\n",
    "    'age_of_vehicle',\n",
    "    'odometer_reading'\n",
    "]\n",
    "categorical_features = [\n",
    "    'customer_type',\n",
    "    'AMC_status'\n",
    "]\n",
    "text_feature = 'customer_feedback'  # raw text\n",
    "\n",
    "# Pipelines\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "text_transformer = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=100)),  # convert text into TF-IDF features\n",
    "])\n",
    "\n",
    "# Combine text sentiment as extra feature\n",
    "class TextFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([TextBlob(str(text)).sentiment.polarity if pd.notna(text) else 0 for text in X]).reshape(-1,1)\n",
    "\n",
    "# Final preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features),\n",
    "    ('text_tfidf', TfidfVectorizer(max_features=100), text_feature)\n",
    "])\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[numeric_features + categorical_features + [text_feature]]\n",
    "y = df['service_urgent']\n",
    "\n",
    "# Split train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build pipeline with feature processor + classifier\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
    "])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict urgency for all\n",
    "df['predicted_urgency'] = model.predict(X)\n",
    "\n",
    "# Segment customers dynamically (could improve with clustering or learned thresholds)\n",
    "def segment(row):\n",
    "    if row['feedback_score'] <= 2 or row['customer_feedback'] in ['Poor Service', 'Unresponsive', 'Delayed Pickup']:\n",
    "        return 'Critical'\n",
    "    elif row['predicted_urgency'] == 1 and row['next_service_due_days'] <= 60:\n",
    "        return 'High Priority'\n",
    "    elif row['predicted_urgency'] == 1:\n",
    "        return 'Medium Priority'\n",
    "    else:\n",
    "        return 'Low Priority'\n",
    "\n",
    "df['customer_segment'] = df.apply(segment, axis=1)\n",
    "\n",
    "# Generate personalized messages (templates or integrate with e.g. GPT for dynamic generation)\n",
    "def gen_message(row):\n",
    "    base = f\"Dear {row['customer_type']} Customer,\\n\"\n",
    "    if row['customer_segment'] == 'Critical':\n",
    "        base += (\"We are sorry for any inconvenience caused and will personally monitor your next service.\\n\"\n",
    "                 \"Enjoy a 15% discount as our apology.\\n\")\n",
    "    elif row['customer_segment'] == 'High Priority':\n",
    "        base += \"Your vehicle requires servicing soon. Book now for priority scheduling.\\n\"\n",
    "    elif row['customer_segment'] == 'Medium Priority':\n",
    "        base += \"Keep your vehicle in top shape by servicing it soon.\\n\"\n",
    "    else:\n",
    "        base += \"Thank you for being a valued customer.\\n\"\n",
    "    base += f\"Service due in {row['next_service_due_days']} days.\\n\"\n",
    "    return base\n",
    "\n",
    "df['personalized_message'] = df.apply(gen_message, axis=1)\n",
    "\n",
    "# Communication channel prediction (you can train a separate model on historical channel success data)\n",
    "# For demo, simple rule-based:\n",
    "def comms_protocol(row):\n",
    "    if row['customer_segment'] == 'Critical':\n",
    "        return ['Phone', 'WhatsApp', 'Email']\n",
    "    elif row['customer_segment'] == 'High Priority':\n",
    "        return ['WhatsApp', 'Email']\n",
    "    else:\n",
    "        return ['Email', 'SMS']\n",
    "\n",
    "df['preferred_channels'] = df.apply(comms_protocol, axis=1)\n",
    "\n",
    "# Save or export result\n",
    "output_cols = ['location', 'customer_type', 'make', 'model', 'year_of_purchase',\n",
    "               'customer_feedback', 'feedback_score', 'next_service_due_days',\n",
    "               'customer_segment', 'personalized_message', 'preferred_channels']\n",
    "\n",
    "reminder_list = df[df['predicted_urgency'] == 1][output_cols]\n",
    "reminder_list.to_csv('ai_based_service_reminder.csv', index=False)\n",
    "print(f\"Saved {len(reminder_list)} reminders.\")\n",
    "\n",
    "# Sample stats\n",
    "print(\"\\nCustomer segments distribution:\")\n",
    "print(reminder_list['customer_segment'].value_counts())\n",
    "\n",
    "# Sample communication channel usage\n",
    "channels = reminder_list['preferred_channels'].explode()\n",
    "print(\"\\nPreferred communication channels distribution:\")\n",
    "print(channels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633ef5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32b6f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score from 5-fold CV: 0.9985 ± 0.0030\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
    "print(f\"Average F1 score from 5-fold CV: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755b1941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'Class_service_reminder_model4.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'Class_service_reminder_model4.pkl')\n",
    "print(\"Model saved as 'Class_service_reminder_model4.pkl'\")\n",
    "\n",
    "# Later, you can load it back as:\n",
    "# loaded_model = joblib.load('Class_service_reminder_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdb1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2372c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23527f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
